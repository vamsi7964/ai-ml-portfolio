{
  "hash": "cf3339847ee206bd764d29e5e9d129a6",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"RoPE vs. absolute positional embeddings (quick visual)\"\ndate: 2025-08-19\ncategories: [NLP, Embeddings, Positional-Encoding]\nimage: assets/og-image.png\n---\n\n**TL;DR**: Absolute positional embeddings add a learned offset per position. **RoPE** rotates pairs of feature dimensions by an angle that depends on the position, letting relative positions emerge *inside* attention.\n\n### One-liner intuition\n- Absolute: \"This token is at index 12.\"\n- RoPE: \"The *relative* angle between tokens carries the position info.\"\n\n::: {#b807fbe9 .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\n\ndef rope_rotate(x, theta):\n    x = x.reshape(-1,2)\n    c, s = np.cos(theta), np.sin(theta)\n    R = np.array([[c,-s],[s,c]])\n    return (x @ R).reshape(-1)\n\nx = np.array([1.0,0.0, 0.5,0.5])\ny = rope_rotate(x, theta=0.3)\nz = rope_rotate(x, theta=0.6)\n(y, z)\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\n(array([ 0.95533649, -0.29552021,  0.62542835,  0.32990814]),\n array([ 0.82533561, -0.56464247,  0.69498904,  0.13034657]))\n```\n:::\n:::\n\n\n",
    "supporting": [
      "2025-08-19-rope-vs-absolute_files"
    ],
    "filters": [],
    "includes": {}
  }
}